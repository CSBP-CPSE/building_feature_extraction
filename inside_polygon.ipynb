{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Find Locations in Polygons\n",
    "\n",
    "This notebook takes in a .kml file of polygons, and a dataset of addresses as inputs. If the polygon contains an address from the dataset, it will be included in a subset .csv of addresses as output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from html.parser import HTMLParser\n",
    "from io import BytesIO,StringIO\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re,os\n",
    "import xml.sax, xml.sax.handler\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "kml_conversion_output = \"gpd\" # Conversion type. Convert .kml to GeoPandas as an intermediate step\n",
    "\n",
    "# User-defined file variables\n",
    "kml_input_filename = \"ottawa-boundary.kml\"\n",
    "address_input_filename = \"geotagged_addresses.csv\"\n",
    "csv_output_filename = \"addresses_inside_polygon.csv\" # The output filename for the .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "KML Conversions Examples\n",
    "----------\n",
    "\n",
    "# output to geopandas\n",
    "a = keyholemarkup2x('LGGWorldCapitals.kmz',output='gpd')\n",
    "\n",
    "# plot this new file, use %matplotlib inline if you are in a notebook\n",
    "#%matplotlib inline\n",
    "a.plot()\n",
    "\n",
    "# convert to shapefile\n",
    "a = keyholemarkup2x('DC_Quadrants.kml',output='shp')\n",
    "\n",
    "# Acknowledgements: \n",
    "KML Conversion\n",
    "https://gist.github.com/linwoodc3/0306734dfe17076dfd34e09660c198c0\n",
    "Linwood Creekmore III (KML Conversion)\n",
    "\n",
    "'''\n",
    "\n",
    "class MyHTMLParser(HTMLParser):\n",
    "    \n",
    "    def __init__(self):\n",
    "        # initialize the base class\n",
    "        HTMLParser.__init__(self)\n",
    "        self.inTable=False\n",
    "        self.mapping = {} \n",
    "        self.buffer = \"\"\n",
    "        self.name_tag = \"\"\n",
    "        self.series = pd.Series()\n",
    "        \n",
    "    def handle_starttag(self, tag, attrs):\n",
    "        if tag == 'table':\n",
    "            self.inTable = True\n",
    "\n",
    "    def handle_data(self, data):\n",
    "        if self.inTable:\n",
    "            self.buffer = data.strip(' \\n\\t').split(':')\n",
    "            if len(self.buffer)==2:\n",
    "                self.mapping[self.buffer[0]]=self.buffer[1]\n",
    "                self.series = pd.Series(self.mapping)\n",
    "        \n",
    "class PlacemarkHandler(xml.sax.handler.ContentHandler):\n",
    "    def __init__(self):\n",
    "        self.inName = False # handle XML parser events\n",
    "        self.inPlacemark = False\n",
    "        self.mapping = {} \n",
    "        self.buffer = \"\"\n",
    "        self.name_tag = \"\"\n",
    "        \n",
    "    def startElement(self, name, attributes):\n",
    "        if name == \"Placemark\": # on start Placemark tag\n",
    "            self.inPlacemark = True\n",
    "            self.buffer = \"\" \n",
    "        if self.inPlacemark:\n",
    "            if name == \"name\": # on start title tag\n",
    "                self.inName = True # save name text to follow\n",
    "            \n",
    "    def characters(self, data):\n",
    "        if self.inPlacemark: # on text within tag\n",
    "            self.buffer += data # save text if in title\n",
    "            \n",
    "    def endElement(self, name):\n",
    "        self.buffer = self.buffer.strip('\\n\\t')\n",
    "        \n",
    "        if name == \"Placemark\":\n",
    "            self.inPlacemark = False\n",
    "            self.name_tag = \"\" #clear current name\n",
    "        \n",
    "        elif name == \"name\" and self.inPlacemark:\n",
    "            self.inName = False # on end title tag            \n",
    "            self.name_tag = self.buffer.strip()\n",
    "            self.mapping[self.name_tag] = {}\n",
    "        elif self.inPlacemark:\n",
    "            if name in self.mapping[self.name_tag]:\n",
    "                self.mapping[self.name_tag][name] += self.buffer\n",
    "            else:\n",
    "                self.mapping[self.name_tag][name] = self.buffer\n",
    "        self.buffer = \"\"\n",
    "        \n",
    "        \n",
    "    def spatializer(row):\n",
    "        \"\"\"\n",
    "        Function to convert string objects to Python spatial objects\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        #############################\n",
    "        # coordinates field\n",
    "        #############################\n",
    "        try:\n",
    "            # look for the coordinates column\n",
    "            data = row['coordinates'].strip(' \\t\\n\\r')\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            import shapely\n",
    "            from shapely.geometry import Polygon,LineString,Point\n",
    "        except ImportError as e:\n",
    "            raise ImportError('This operation requires shapely. {0}'.format(e))\n",
    "        import ast\n",
    "        lsp = data.strip().split(' ')\n",
    "        linestring = map(lambda x: ast.literal_eval(x),lsp)\n",
    "        try:\n",
    "            spatial = Polygon(LineString(linestring))\n",
    "            convertedpoly = pd.Series({'geometry':spatial})\n",
    "            return convertedpoly\n",
    "        except:\n",
    "            try:\n",
    "                g = ast.literal_eval(data)\n",
    "                points = pd.Series({'geometry':Point(g[:2]),\n",
    "                                   'altitude':g[-1]})\n",
    "                return points\n",
    "            except:\n",
    "            \n",
    "                pass\n",
    "            \n",
    "        \n",
    "        \n",
    "        try:\n",
    "            # Test for latitude and longitude columns\n",
    "            lat=float(row['latitude'])\n",
    "            lon=float(row['longitude'])\n",
    "            point = Point(lon,lat)\n",
    "            convertedpoly = pd.Series({'geometry':point})\n",
    "            return convertedpoly\n",
    "        except:\n",
    "            \n",
    "            pass\n",
    "    \n",
    "    def htmlizer(row):\n",
    "        htmlparser = MyHTMLParser()\n",
    "        htmlparser.feed(row['description'])\n",
    "        return htmlparser.series\n",
    "        \n",
    "        \n",
    "def keyholemarkup2x(file,output='df'):\n",
    "    \"\"\"\n",
    "    Takes Keyhole Markup Language Zipped (KMZ) or KML file as input. The  \n",
    "    output is a pandas dataframe, geopandas geodataframe, csv, geojson, or\n",
    "    shapefile.\n",
    "    \n",
    "    All core functionality from:\n",
    "    http://programmingadvent.blogspot.com/2013/06/kmzkml-file-parsing-with-python.html\n",
    "    \n",
    "    Parameters\n",
    "        ----------\n",
    "        file : {string}\n",
    "            The string path to your KMZ or .\n",
    "        output : {string}\n",
    "            Defines the type of output. Valid selections include:\n",
    "                - shapefile - 'shp', 'shapefile', or 'ESRI Shapefile'\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "    \"\"\"\n",
    "    r = re.compile(r'(?<=\\.)km+[lz]?',re.I)\n",
    "    try:\n",
    "        extension = r.search(file).group(0) #(re.findall(r'(?<=\\.)[\\w]+',file))[-1]\n",
    "        \n",
    "    \n",
    "    except IOError as e:\n",
    "        logging.error(\"I/O error {0}\".format(e))\n",
    "    if (extension.lower()=='kml') is True:\n",
    "        buffer = file\n",
    "    elif (extension.lower()=='kmz') is True:\n",
    "        kmz = ZipFile(file, 'r')\n",
    "        \n",
    "        vmatch = np.vectorize(lambda x:bool(r.search(x)))\n",
    "        A = np.array(kmz.namelist())\n",
    "        sel = vmatch(A)\n",
    "        buffer = kmz.open(A[sel][0],'r')\n",
    "    \n",
    "    else:\n",
    "        raise ValueError('Incorrect file format entered.  Please provide the '\n",
    "                         'path to a valid KML or KMZ file.')    \n",
    "     \n",
    "    \n",
    "    parser = xml.sax.make_parser()\n",
    "    handler = PlacemarkHandler()\n",
    "    parser.setContentHandler(handler)\n",
    "    parser.parse(buffer)\n",
    "    \n",
    "    try:\n",
    "        kmz.close()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    df = pd.DataFrame(handler.mapping).T\n",
    "    names = list(map(lambda x: x.lower(),df.columns))\n",
    "    if 'description' in names:\n",
    "        extradata = df.apply(PlacemarkHandler.htmlizer,axis=1)\n",
    "        df = df.join(extradata)\n",
    "    \n",
    "    \n",
    "    output = output.lower()\n",
    "    \n",
    "    if output=='df' or output=='dataframe' or output == None:\n",
    "        result = df\n",
    "        \n",
    "    elif output=='csv':\n",
    "        out_filename = file[:-3] + \"csv\"\n",
    "        df.to_csv(out_filename,encoding='utf-8',sep=\"\\t\")\n",
    "        result = (\"Successfully converted {0} to CSV and output to\"\n",
    "                   \" disk at {1}\".format(file,out_filename))\n",
    "        \n",
    "    elif output=='gpd' or output == 'gdf' or output=='geoframe' or output == 'geodataframe':\n",
    "        try:\n",
    "            import shapely\n",
    "            from shapely.geometry import Polygon,LineString,Point\n",
    "        except ImportError as e:\n",
    "            raise ImportError('This operation requires shapely. {0}'.format(e))\n",
    "        try:\n",
    "            import fiona\n",
    "        except ImportError as e:\n",
    "            raise ImportError('This operation requires fiona. {0}'.format(e))\n",
    "        try:\n",
    "            import geopandas as gpd\n",
    "        except ImportError as e:\n",
    "            raise ImportError('This operation requires geopandas. {0}'.format(e))\n",
    "            \n",
    "        geos = gpd.GeoDataFrame(df.apply(PlacemarkHandler.spatializer,axis=1))\n",
    "        result = gpd.GeoDataFrame(pd.concat([df,geos],axis=1))\n",
    "        \n",
    "        \n",
    "    elif output=='geojson' or output=='json':\n",
    "        try:\n",
    "            import shapely\n",
    "            from shapely.geometry import Polygon,LineString,Point\n",
    "        except ImportError as e:\n",
    "            raise ImportError('This operation requires shapely. {0}'.format(e))\n",
    "        try:\n",
    "            import fiona\n",
    "        except ImportError as e:\n",
    "            raise ImportError('This operation requires fiona. {0}'.format(e))\n",
    "        try:\n",
    "            import geopandas as gpd\n",
    "        except ImportError as e:\n",
    "            raise ImportError('This operation requires geopandas. {0}'.format(e))\n",
    "        try:\n",
    "            import geojson\n",
    "        except ImportError as e:\n",
    "            raise ImportError('This operation requires geojson. {0}'.format(e))\n",
    "            \n",
    "        geos = gpd.GeoDataFrame(df.apply(PlacemarkHandler.spatializer,axis=1))\n",
    "        gdf = gpd.GeoDataFrame(pd.concat([df,geos],axis=1))\n",
    "        out_filename = file[:-3] + \"geojson\"\n",
    "        gdf.to_file(out_filename,driver='GeoJSON')\n",
    "        validation = geojson.is_valid(geojson.load(open(out_filename)))['valid']\n",
    "        if validation == 'yes':\n",
    "            \n",
    "            result = (\"Successfully converted {0} to GeoJSON and output to\"\n",
    "                      \" disk at {1}\".format(file,out_filename))\n",
    "        else:\n",
    "            raise ValueError('The geojson conversion did not create a '\n",
    "                            'valid geojson object. Try to clean your '\n",
    "                            'data or try another file.')\n",
    "            \n",
    "    elif output=='shapefile' or output=='shp' or output =='esri shapefile':\n",
    "        try:\n",
    "            import shapely\n",
    "            from shapely.geometry import Polygon,LineString,Point\n",
    "        except ImportError as e:\n",
    "            raise ImportError('This operation requires shapely. {0}'.format(e))\n",
    "        try:\n",
    "            import fiona\n",
    "        except ImportError as e:\n",
    "            raise ImportError('This operation requires fiona. {0}'.format(e))\n",
    "            \n",
    "        try:\n",
    "            import geopandas as gpd\n",
    "        except ImportError as e:\n",
    "            raise ImportError('This operation requires geopandas. {0}'.format(e))\n",
    "            \n",
    "        try:\n",
    "            import shapefile\n",
    "        except ImportError as e:\n",
    "            raise ImportError('This operation requires pyshp. {0}'.format(e))\n",
    "        \n",
    "            \n",
    "        geos = gpd.GeoDataFrame(df.apply(PlacemarkHandler.spatializer,axis=1))\n",
    "        gdf = gpd.GeoDataFrame(pd.concat([df,geos],axis=1))\n",
    "        out_filename = file[:-3] + \"shp\"\n",
    "        gdf.to_file(out_filename,driver='ESRI Shapefile')\n",
    "        sf = shapefile.Reader(out_filename)\n",
    "        import shapefile\n",
    "        sf = shapefile.Reader(out_filename)\n",
    "        if len(sf.shapes())>0:\n",
    "            validation = \"yes\"\n",
    "        else:\n",
    "            validation = \"no\"\n",
    "        if validation == 'yes':\n",
    "            \n",
    "            result = (\"Successfully converted {0} to Shapefile and output to\"\n",
    "                      \" disk at {1}\".format(file,out_filename))\n",
    "        else:\n",
    "            raise ValueError('The Shapefile conversion did not create a '\n",
    "                            'valid shapefile object. Try to clean your '\n",
    "                            'data or try another file.') \n",
    "    else:\n",
    "        raise ValueError('The conversion returned no data; check if'\n",
    "                        ' you entered a correct output file type. '\n",
    "                        'Valid output types are geojson, shapefile,'\n",
    "                        ' csv, geodataframe, and/or pandas dataframe.')\n",
    "        \n",
    "    return result\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .kml conversion to GeoPandas DataFrame\n",
    "kml_df = keyholemarkup2x(kml_input_filename, output=kml_conversion_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the addresses into a GeoPandas Data\n",
    "address_database = gpd.read_file(address_input_filename)\n",
    "address_database.longitude = address_database.longitude.astype('float')\n",
    "address_database.latitude = address_database.latitude.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the lon lat to Point objects and add to the geometry \n",
    "address_database.geometry=gpd.points_from_xy(address_database.longitude, address_database.latitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "address_database[\"inPolygon\"] = None # Create and  initialize the inPolygon column\n",
    "# If the Point is within the Polygon, mark the column value to True, otherwise do nothing\n",
    "for polygon in kml_df[\"geometry\"]:\n",
    "    address_database[\"inPolygon\"] = np.where(address_database[\"geometry\"].within(polygon),True,address_database[\"inPolygon\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a results dataframe to store the True results\n",
    "results_df = address_database[address_database['inPolygon'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Clean output for next script\n",
    "results_df = results_df.drop(columns=\"inPolygon\")\n",
    "results_df = results_df.drop(columns=\"geometry\")\n",
    "results_df = results_df.drop(columns=\"latitude\")\n",
    "results_df = results_df.drop(columns=\"longitude\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create .csv of final results\n",
    "results_df.to_csv(csv_output_filename, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "metadata": {
   "interpreter": {
    "hash": "2c0fb3fde6fa56fb637e6e50ae60167f055867ed321f80f3a42c244d6dc3f8b1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
